{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO`:\n",
    "- [ ] revise outline below to match flow of `expt1_dev.py`\n",
    "- [ ] abstract over params in `expt1_dev.py`\n",
    "- [ ] once finished w `expt1_dev.py`, move it to this nb\n",
    "- [ ] figger out clean way to do imports for class module (tricky) \n",
    "- [ ] decide whether to use wrapper classes at all\n",
    "- [ ] determine if TypeC even needs a class (def needs minimal text prep)\n",
    "- [ ] add sub-expt w train on ~70% and eval on length subsets \n",
    "- [ ] write + test out crossval func that can apply to any of the clf types\n",
    "\n",
    "\n",
    "> **Note**: old version of this nb w outdated outline etc. now lives in `'/ignore/scrapped-but-useful'` (new version is `'/experiments/expt1/expt1.ipynb'`)\n",
    "\n",
    "<hr><hr>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "#### Document length and classification accuracy\n",
    "<hr>\n",
    "\n",
    "###### Part 1: Define experiment \n",
    "1. define space of classifiers (and hypers) to consider \n",
    "2. import classes for managing arbitrary `sklearn` and `keras` models \n",
    "3. write model evaluation function \n",
    "4. write performance curve flattener \n",
    "\n",
    "###### Part 2: Prepare data \n",
    "1. import text preprocessing functions/classes \n",
    "2. load and preprocess text (need >1 format for diff clf styles)\n",
    "3. split data into length subsets \n",
    "4. set aside 30% of data for evaluation, stratified by length and label\n",
    "\n",
    "###### Part 3: Conduct experiment \n",
    "1. for each train subset, get 5-fold crossval F1 for each clf\n",
    "2. for each fit, generate and save preds on evaluation set \n",
    "\n",
    "###### Part 4: Evaluate results\n",
    "1. plot the crossval F1 scores across subsets and clfs\n",
    "2. plot performance on validation set for each clf and subset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Part 1: Define experiment\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Define space of classifiers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Import what's needed for each model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Import what's needed for preprocssing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Import what's needed for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5 Import what's needed for postprocessing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Part 2: Prepare data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Part 3: Conduct experiment\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Part 4: Evaluate results\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "<hr><hr>\n",
    "### sqrache areyaya"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
