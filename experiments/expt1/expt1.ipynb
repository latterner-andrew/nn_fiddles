{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "#### Document length and classification accuracy\n",
    "<hr>\n",
    "\n",
    "###### Part 1: Define experiment \n",
    "1. define space of classifiers (and hypers) to consider \n",
    "2. write function(s) to train arbitrary clfs and predict \n",
    "3. write model evaluation function \n",
    "4. write performance curve plotting function \n",
    "\n",
    "###### Part 2: Prepare data \n",
    "1. load and split data into length subsets \n",
    "2. set aside 30% of data for evaluation (stratified)\n",
    "3. write function(s) to preprocess text (two options)\n",
    "\n",
    "###### Part 3: Conduct experiment \n",
    "1. for each train subset, get 5-fold crossval F1 for each clf\n",
    "2. for each fit, generate and save preds on evaluation set \n",
    "\n",
    "\n",
    "###### Part 4: Evaluate results\n",
    "1. plot the crossval F1 scores across subsets and clfs\n",
    "2. plot performance on validation set for each clf and subset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Part 1: Define experiment\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Define space of classifiers \n",
    "\n",
    "We will consider the following set of classification strategies:\n",
    "\n",
    "- `Type A:` Non-NN: \n",
    "    - Multinomial Naive Bayes\n",
    "    - Support Vector Machine\n",
    "- `Type B:` Feed-forward NN classifiers: \n",
    "    - Multilayer Perceptron\n",
    "    - Convolutional NN\n",
    "- `Type C:` Recurrent NN classifiers: \n",
    "    - LSTM Network \n",
    "    - Bi-directional RNN\n",
    "\n",
    "> *Note:* `Type C` algorithms take sequence data as input (padded token sequences), whereas `Type A` and `Type B` take DTM-type structures as input (vectorized sequences).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Write wrapper class for each model type \n",
    "\n",
    "Define classes `TypeA`, `TypeB`, and `TypeC`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.2.1 Define class for `TypeA` classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeA():\n",
    "  '''Wrapper class for `sklearn` binary text classifiers \n",
    "  \n",
    "  on init:\n",
    "    - instantiate `Classifier` class, with params given by `**kwargs`\n",
    "    - store `Classifier.__name__` and param key-vals in .clf_info attr \n",
    "  methods:\n",
    "    - .train(train_dtm, train_labels): call .clf.fit() on dtm and labels\n",
    "    - .predict(test_dtm): generate predictions over unseen input data \n",
    "  \n",
    "  attributes:\n",
    "    - .clf: `sklearn.*.Classifier` instance\n",
    "    - .clf_info: dict, stores classifier name and param key-value pairs \n",
    "    - .train_dtm, .train_labels: input data and labels fed to .train()\n",
    "  \n",
    "  usage example: \n",
    "    ```\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    skl_clf = MultinomialNB\n",
    "    skl_clf_params = {'alpha': .9, 'fit_prior': True}\n",
    "    \n",
    "    # suppose `dat` as a df with columns `subset` (train, test) and `text` \n",
    "    train = dat[dat.subset=='train']\n",
    "    test = dat[dat.subset=='test']\n",
    "    \n",
    "    train_text, train_labels = train.text, train.label\n",
    "    test_text, test_labels = test.text, test.label\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_dtm = vectorizer.fit_transform(train_text)\n",
    "    test_dtm = vectorizer.transform(test_text)\n",
    "    \n",
    "    classifier = TypeA(skl_clf, **skl_clf_params)\n",
    "    classifier.train(train_dtm, train_labels)\n",
    "    # print(classifier.clf_info)\n",
    "    \n",
    "    preds = classifier.predict(test_dtm)\n",
    "    # print(sum([pred==obs for pred,obs in zip(preds,test_labels)]))\n",
    "    print('f1 score on test set:', round(f1_score(test_labels, preds), 3))\n",
    "    ```\n",
    "  \n",
    "  TODO:\n",
    "    - want to save weight matrix as an attr??\n",
    "    - check handling of **kwargs \n",
    "    - ... \n",
    "  '''\n",
    "  def __init__(self, Classifier, **kwargs):\n",
    "    self.clf = Classifier(**kwargs)\n",
    "    self.clf_info = dict({'clf' : Classifier.__name__}, **kwargs)\n",
    "  \n",
    "  def train(self, train_dtm, train_labels):\n",
    "    self.train_dtm, self.train_labels = train_dtm, train_labels\n",
    "    self.clf.fit(self.train_dtm, self.train_labels)\n",
    "  \n",
    "  def predict(self, test_dtm):\n",
    "    test_preds = self.clf.predict(test_dtm)\n",
    "    return test_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.2.2 Define class for `TypeB` classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeB():\n",
    "  '''Wrapper class for managing `keras.models.Sequential()` models\n",
    "  \n",
    "  on init: \n",
    "    - instantiates keras model \n",
    "    - adds supplied layers (if any)\n",
    "    - sets a few attrs used during train/compile/predict \n",
    "  \n",
    "  methods:\n",
    "    - add_layers(layers_list, kwargs_list)\n",
    "    - compile_model(optimizer, loss, metrics)\n",
    "    - train(train_X, train_y, valset_prop, epochs, batch_size)\n",
    "    - predict()\n",
    "  \n",
    "  attributes:\n",
    "    - .model: instance of KerasModel class passed on init \n",
    "    - .layers_info: list of dicts with params and type of each layer \n",
    "    - .is_compiled, .layers_added: boolean, for tracking model state \n",
    "    - .train_X, .train_y: train data and labels, appropriately preprocessed\n",
    "    - .history: a keras History object with info about training history  \n",
    "  \n",
    "  usage example:\n",
    "    ```\n",
    "    from keras.layers import Dense\n",
    "    \n",
    "    vocab_n = 10000\n",
    "    layers = [Dense, Dense, Dense]\n",
    "    kwargss = [dict(units=16, activation='relu', input_shape=(vocab_n)), \n",
    "               dict(units=16, activation='relu'), \n",
    "               dict(units=1, activation='sigmoid')]\n",
    "    neural_net = TypeB(keras.models.Sequential, layers, kwargss)\n",
    "    neural_net.compile_model(optimizer='rmsprop', \n",
    "                             loss='binary_crossentropy', \n",
    "                             metrics = ['accuracy'])\n",
    "    # with appropriately preprocessed `train_X` and `train_y`\n",
    "    neural_net.train(train_X,train_y, valset_prop=.3,epochs=7,batch_size=50)\n",
    "    \n",
    "    preds = neural_net.predict(test_X, pred_postprocessor=lambda x: x > .5)\n",
    "    sum([pred==true for pred, true in zip(preds, test_y)]) / len(test_y)\n",
    "    ```\n",
    "  \n",
    "  TODO: \n",
    "    - can have multiple histories?? (if so, maybe append to lsit instead)\n",
    "    - need to pass anything to KerasModel?!\n",
    "    - track layer indices in .layers_info?! \n",
    "    - add print and/or repr and/or display method?!?! \n",
    "    - abstract over **kwargs for .compile_model()\n",
    "    - abstract over **kwargs for .train()  \n",
    "    - ... \n",
    "  '''\n",
    "  def __init__(self, KerasModel, layers_list=[], kwargs_list=[]):\n",
    "    self.model = KerasModel()\n",
    "    self.layers_info = []\n",
    "    self.is_compiled = False\n",
    "    self.layers_added = False\n",
    "    \n",
    "    assert len(layers_list) == len(kwargs_list)\n",
    "    if len(layers_list) > 0: self.add_layers(layers_list, kwargs_list)\n",
    "  \n",
    "  def add_layers(self, layers_list, kwargs_list):\n",
    "    for layer, kwargs in zip(layers_list, kwargs_list):\n",
    "      self.model.add(layer(kwargs))\n",
    "      # TODO: FIX THIS (SEE TypeA FIX ABOVE)\n",
    "      self.layers_info.append(kwargs.update({'layer': layer.__name__}))\n",
    "    self.layers_added = True\n",
    "  \n",
    "  def compile_model(self, optimizer, loss, metrics):\n",
    "    assert self.layers_added, 'must add layers to model before compiling!'\n",
    "    self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    self.is_compiled = True\n",
    "  \n",
    "  def train(self, train_X, train_y, valset_prop, epochs, batch_size):\n",
    "    self.train_X, self.train_y = train_X, train_y\n",
    "    assert len(self.train_X) == len(self.train_y)\n",
    "    assert self.is_compiled, 'must compile model before training!'\n",
    "    valset_size = round(valset_prop * len(self.train_y))\n",
    "    trn_X, val_X = self.train_X[valset_size:], self.train_X[:valset_size]\n",
    "    trn_y, val_y = self.train_y[valset_size:], self.train_y[:valset_size]\n",
    "    self.history = self.model.fit(trn_X, trn_y, \n",
    "                                  epochs=epochs, batch_size=batch_size, \n",
    "                                  validation_data=(val_X, val_y))\n",
    "  \n",
    "  def predict(self, test_X, pred_postprocessor=lambda x: x):\n",
    "    test_probs = self.model.predict(test_X)\n",
    "    test_preds = [pred_postprocessor(prob) for prob in test_probs]\n",
    "    return test_preds\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.2.3 Define class for `TypeC` classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe not even necessary?! \n",
    "# maybe `TypeC` interface same as `TypeB` since both are keras?! \n",
    "# class TypeC(): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Write function to evaluate performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility func to convert a probability into a binary prediction \n",
    "def prob_to_binary(prob, threshold=.5, ret_type=bool):\n",
    "  assert 0 <= prob <= 1\n",
    "  assert 0 <= threshold <= 1\n",
    "  return ret_type(prob > threshold)\n",
    "\n",
    "\n",
    "def evaluate_model(trained_model, test_data, test_labels, metric):\n",
    "  test_preds = trained_model.predict(test_data)\n",
    "  return metric(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Write function to plot performance curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Part 2: Prepare data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Load and split data into length subsets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Set aside stratified evaluation data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Write functions to preprocess text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Part 3: Conduct experiment\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.0 Check that classes work as designed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file = 'data/imdb_decoded.csv'\n",
    "dat = pd.read_csv(data_file)\n",
    "\n",
    "\n",
    "display(dat.head())\n",
    "print(f'shape of full data: {dat.shape[0]}x{dat.shape[1]}')\n",
    "# print('label distro:\\n', dat.label.value_counts())\n",
    "# print('length bin sizes:\\n', dat.length_bin.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TypeA example \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "skl_clf = MultinomialNB\n",
    "skl_clf_params = {'alpha': .9, 'fit_prior': True}\n",
    "\n",
    "# suppose `dat` as a df with columns `subset` (train, test) and `text` \n",
    "train = dat[dat.subset=='train']\n",
    "test = dat[dat.subset=='test']\n",
    "\n",
    "train_text, train_labels = train.text, train.label\n",
    "test_text, test_labels = test.text, test.label\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_dtm = vectorizer.fit_transform(train_text)\n",
    "test_dtm = vectorizer.transform(test_text)\n",
    "\n",
    "classifier = TypeA(skl_clf, **skl_clf_params)\n",
    "classifier.train(train_dtm, train_labels)\n",
    "# print(classifier.clf_info)\n",
    "\n",
    "preds = classifier.predict(test_dtm)\n",
    "# print(sum([pred==obs for pred,obs in zip(preds,test_labels)]))\n",
    "print('f1 score on test set:', round(f1_score(test_labels, preds), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TypeB example\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vocab_n = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_n)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "train_encoded = tokenizer.texts_to_sequences(train_text)\n",
    "train_dtm = tokenizer.sequences_to_matrix(train_encoded, mode='count')\n",
    "\n",
    "test_encoded = tokenizer.texts_to_sequences(test_text)\n",
    "test_dtm = tokenizer.sequences_to_matrix(test_encoded, mode='count')\n",
    "\n",
    "print(train_dtm.shape)\n",
    "print(test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [layers.Dense, layers.Dense, layers.Dense]\n",
    "\n",
    "kwargs_list = [dict(units=16, activation='relu', input_shape=(vocab_n)), \n",
    "               dict(units=16, activation='relu'), \n",
    "               dict(units=1, activation='sigmoid')]\n",
    "\n",
    "# TODO: START HERE!!! (IN PROCESS OF DEBUGGING `TypeB` CLASS!!! )\n",
    "# TODO: START HERE!!! (IN PROCESS OF DEBUGGING `TypeB` CLASS!!! )\n",
    "# TODO: START HERE!!! (IN PROCESS OF DEBUGGING `TypeB` CLASS!!! )\n",
    "# TODO: START HERE!!! (IN PROCESS OF DEBUGGING `TypeB` CLASS!!! )\n",
    "# TODO: START HERE!!! (IN PROCESS OF DEBUGGING `TypeB` CLASS!!! )\n",
    "neural_net = TypeB(models.Sequential, layer_list, kwargs_list)\n",
    "\n",
    "\n",
    "neural_net.compile_model(optimizer='rmsprop', \n",
    "                         loss='binary_crossentropy', \n",
    "                         metrics = ['accuracy'])\n",
    "\n",
    "# with appropriately preprocessed `train_X` and `train_y`\n",
    "neural_net.train(train_dtm, train_labels,\n",
    "                 valset_prop=.3, epochs=3, batch_size=50)\n",
    "\n",
    "# preds = neural_net.predict(test_X, pred_postprocessor=lambda x: x > .5)\n",
    "# sum([pred==true for pred, true in zip(preds, test_y)]) / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: `expt1_util` module not ready to be used \n",
    "# # this works fine but then there is awkward train-test split \n",
    "# from expt1_util import docs_to_dtm\n",
    "# alltext_dtm = docs_to_dtm(docs=dat.text, mode='count', num_words=vocab_n)\n",
    "# print(len(alltext_dtm))\n",
    "# print(alltext_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Get 5-fold crossval F1 for each clf across train subsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Generate predictions on evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Train on random 70% subset, evaluate across subsets on remaining 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Part 4: Evaluate results\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Plot CV scores across subsets and clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Plot performance on holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "<hr><hr>\n",
    "### sqrache areyaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def boosh(x, **kwargs):\n",
    "  print(f'x is {x}...')\n",
    "  return np.random.normal(**kwargs)\n",
    "\n",
    "def boosh2(f_list, kwargs_list):\n",
    "  assert len(f_list) == len(kwargs_list)\n",
    "  for f, kwargs in zip(f_list, kwargs_list):\n",
    "    val = f(**kwargs)\n",
    "    print(f'{f.__name__} applied to kwargs: {val}')\n",
    "\n",
    "\n",
    "# kw = dict(loc=1, scale=2, size=3)\n",
    "# np.random.normal(**kw)\n",
    "# boosh(3, **kw)\n",
    "\n",
    "# np.random.exponential(scale=1.0, size=5)\n",
    "# np.random.chisquare(df, size=1)\n",
    "\n",
    "\n",
    "fs = [np.random.normal, np.random.exponential, np.random.chisquare]\n",
    "kwargss = [dict(loc=1, scale=2, size=3), \n",
    "           dict(scale=2.0, size=2), \n",
    "           dict(df=2, size=1)]\n",
    "np.random.seed(6933)\n",
    "boosh2(fs, kwargss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# not exist! keras.History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1,2,3]\n",
    "l2 = ['a','b','c']\n",
    "\n",
    "for idx, (x, y) in enumerate([*zip(l1,l2)]):\n",
    "  print(idx, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
