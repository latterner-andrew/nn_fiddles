{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf fiddle with imdb sentiment dataset \n",
    "###### [last update: aug29/2018]\n",
    "<hr><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### useful links etc.\n",
    "\n",
    "- [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) for dataset `tf.keras.datasets.imdb`\n",
    "- [explanation](https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset) of weird quasi-BoW format for input features\n",
    "  - see accepted answer for ex of restoring text; \n",
    "  - see second answer for original text. \n",
    "- examples of analyses using this dataset:\n",
    "  - ... \\[insert\\]\n",
    "  - ... \\[insert\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is 80 chars, just for reference (no vertical rule in jupyterlab?! </3)\n",
    "## ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. setup \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 load imdb sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imdb sentiment data \n",
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# ys: each a binary label, xs: each a review coded as int array\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### define some utilities for handling text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict associating int indices w words \n",
    "wdict = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcs for translating between words and indices \n",
    "\n",
    "# get a word's numeric index \n",
    "def w_to_idx(w):\n",
    "  return wdict[w]\n",
    "\n",
    "# get an index's corresponding word \n",
    "def idx_to_w(widx):\n",
    "  return [w for w, idx in wdict.items() if idx == widx][0]\n",
    "\n",
    "# TODO: \n",
    "#   - figure out which is more efficient for idx_to_w():\n",
    "#       current; or \n",
    "#       next((w for w, idx in wdict.items() if idx==widx),None); or \n",
    "#       e.g. [w for w, idx in wdict.items() if idx in widxs]\n",
    "#   - return individual idx/word or lists of them?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. show structure of data and demo utils\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 basic data properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of test and train sets \n",
    "print(f'train n: {len(y_train)}, test n: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first few train labels, unique label vals, and train freqs \n",
    "print(y_train[:10], np.unique(y_train, return_counts=True), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first train input \n",
    "# (corresponding label for x == y_train[0] == 1)\n",
    "x = x_train[0] \n",
    "\n",
    "print(x[:10],     # first ten elements \n",
    "      len(x),     # length is 218\n",
    "      type(x),    # x is a list... \n",
    "      type(x[0]), # of ints\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 example usage for utils `w_to_idx()`, and `idx_to_w()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example word indices and words \n",
    "widxs = [2289, 70691, 10092]\n",
    "words = ['woody', 'boosh', 'yikes']\n",
    "\n",
    "# get a word from idx, or vice versa \n",
    "print('idx', w_to_idx('woody'), 'is word', idx_to_w(2289))\n",
    "\n",
    "# get a list of words from list of idxs, or vice versa \n",
    "print('words for `widxs`: ', [idx_to_w(idx) for idx in widxs])\n",
    "print('idxs  for `words`: ', [w_to_idx(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate init segment of a review from idxs to words \n",
    "# [note that x inputs already just bags of lowercase words]\n",
    "print('first five word indices:', x[:5])\n",
    "print('word translations:', [idx_to_w(idx) for idx in x[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. train + eval a couple of `sklearn` classifiers\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### re-encode preprocessed features to facilitate usual sklearn workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: CURRENTLY THIS IS WAYYYYYY TOO SLOW. SO EITHER\n",
    "###    - FIND A MORE EFFICIENT WAY; OR\n",
    "###    - USE LINK IN NOTES AT TOP OF NB TO FIND RAWER VERSION...\n",
    "\n",
    "\n",
    "# re-encode a doc as a string of its words (a 'quasi-document') \n",
    "def idxlist_to_quasi_doc(x):\n",
    "  return ' '.join([idx_to_w(idx) for idx in x])\n",
    "\n",
    "# since test/train are same size, can create qd-lists simultaneously\n",
    "quasi_docs_train = []\n",
    "quasi_docs_test = []\n",
    "\n",
    "for xidx in range(len(x_train)): \n",
    "  if not xidx % 10: print(f'on iter `{xidx}` of `{len(x_test)}`...')\n",
    "  quasi_docs_train.append(idxlist_to_quasi_doc(x_train[xidx]))\n",
    "  quasi_docs_test.append(idxlist_to_quasi_doc(x_test[xidx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 multinomial naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_mnb = MultinomialNB()\n",
    "clf_mnb.fit(X=x_train, y=y_train)\n",
    "# preds_mnb = clf_mnb.predict(X=x_test)\n",
    "# accuracy_score(y_true=y_test, y_pred=preds_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 support vector machine  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
