{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing with `keras` versus `sklearn`\n",
    "<hr>\n",
    "\n",
    "Preprocessing text data for modeling can be done in a number of ways. The default workflow enabled by `keras.preprocessing.text.Tokenizer` appears to be somewhat different from that of `sklearn.feature_extraction.text.CountVectorizer`, which creates a count-based document-term matrix (DTM) from a set of documents (\"corpus\"). \n",
    "\n",
    "However, the differences are superficial in nature and the same DTM can be created easily with either workflow. The only meaningful difference appears to be a cultural one: in `keras` examples, DTMs are usually *binary*, not count-based. Binary DTMs can be created with `sklearn` by setting `binary=True` on instantiation of `CountVectorizer()`. And count-based DTMs can be created with `keras` by setting `mode='count'` on instantiation of `Tokenizer()`. \n",
    "\n",
    "\n",
    "This notebook demonstrates...\n",
    "\n",
    "1. how to create a count-based DTM with the `sklearn` preprocessing workflow \n",
    "2. how to create a count-based DTM with the `keras` preprocessing workflow \n",
    "3. that the two strategies produce equivalent results \n",
    "\n",
    "Whether the `keras` cultural norm of using binary DTMs is important for classification accuracy will be assessed in a subsequent notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. create a toy corpus\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['this is me toy corp', 'a corp is just a bunch of docs', \n",
    "        'a doc is just a string', 'a string is just some chars',\n",
    "        'and this doc is a doc and the last doc of the docs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. construct count DTM with `keras` workflow\n",
    "<hr>\n",
    "\n",
    "- take the docs\n",
    "- tokenize them with `Tokenizer.fit_on_texts()` \n",
    "- integer-encode them with `Tokenizer.texts_to_sequences()`  \n",
    "- count-vectorize the integer tokens with `Tokenizer.sequences_to_matrix()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# instantiate Tokenizer class (`num_words` to restrict vocab size)\n",
    "tokenizer = Tokenizer(num_words=None)\n",
    "\n",
    "# extract vocab and count words (makes several attrs available) \n",
    "tokenizer.fit_on_texts(docs)\n",
    "\n",
    "# integer encode the documents \n",
    "docs_int_encoded = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "# transform encoded docs into a DTM (default is binary)\n",
    "# `mode` can be one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
    "dtm_countK = tokenizer.sequences_to_matrix(docs_int_encoded, mode='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. construct count DTM with `sklearn` workflow\n",
    "<hr>\n",
    "\n",
    "- take the docs\n",
    "- construct DTM directly with `CountVectorizer.fit_transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# don't want the default two-character restriction on words \n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')\n",
    "\n",
    "dtm_countSKL = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. show that the two approaches yield equivalent results\n",
    "<hr>\n",
    "\n",
    "The columns are in different orders because the two tokenizers work differently internally. But the column contents are identical across the two data frames. Note also that `keras` reserves the vocabulary index `0`, which is why the placeholder character `<>` is shown as the first column header in the first df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count DTM from keras.preprocessing.text.Tokenizer():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;&gt;</th>\n",
       "      <th>a</th>\n",
       "      <th>is</th>\n",
       "      <th>doc</th>\n",
       "      <th>just</th>\n",
       "      <th>this</th>\n",
       "      <th>corp</th>\n",
       "      <th>of</th>\n",
       "      <th>docs</th>\n",
       "      <th>string</th>\n",
       "      <th>and</th>\n",
       "      <th>the</th>\n",
       "      <th>me</th>\n",
       "      <th>toy</th>\n",
       "      <th>bunch</th>\n",
       "      <th>some</th>\n",
       "      <th>chars</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   <>  a  is  doc  just  this  corp  of  docs  string  and  the  me  toy  \\\n",
       "0   0  0   1    0     0     1     1   0     0       0    0    0   1    1   \n",
       "1   0  2   1    0     1     0     1   1     1       0    0    0   0    0   \n",
       "2   0  2   1    1     1     0     0   0     0       1    0    0   0    0   \n",
       "3   0  1   1    0     1     0     0   0     0       1    0    0   0    0   \n",
       "4   0  1   1    3     0     1     0   1     1       0    2    2   0    0   \n",
       "\n",
       "   bunch  some  chars  last  \n",
       "0      0     0      0     0  \n",
       "1      1     0      0     0  \n",
       "2      0     0      0     0  \n",
       "3      0     1      1     0  \n",
       "4      0     0      0     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count DTM from sklearn.feature_extraction.text.CountVectorizer():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>bunch</th>\n",
       "      <th>chars</th>\n",
       "      <th>corp</th>\n",
       "      <th>doc</th>\n",
       "      <th>docs</th>\n",
       "      <th>is</th>\n",
       "      <th>just</th>\n",
       "      <th>last</th>\n",
       "      <th>me</th>\n",
       "      <th>of</th>\n",
       "      <th>some</th>\n",
       "      <th>string</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>toy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  and  bunch  chars  corp  doc  docs  is  just  last  me  of  some  \\\n",
       "0  0    0      0      0     1    0     0   1     0     0   1   0     0   \n",
       "1  2    0      1      0     1    0     1   1     1     0   0   1     0   \n",
       "2  2    0      0      0     0    1     0   1     1     0   0   0     0   \n",
       "3  1    0      0      1     0    0     0   1     1     0   0   0     1   \n",
       "4  1    2      0      0     0    3     1   1     0     1   0   1     0   \n",
       "\n",
       "   string  the  this  toy  \n",
       "0       0    0     1    1  \n",
       "1       0    0     0    0  \n",
       "2       1    0     0    0  \n",
       "3       1    0     0    0  \n",
       "4       0    2     1    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "# get vocab for each approach in correct order to make column names \n",
    "vocabK = list(tokenizer.word_index.keys())\n",
    "vocabSKL = vectorizer.get_feature_names()\n",
    "\n",
    "# get both dtms as dataframes and compare side-by-side\n",
    "dtm_df_K = DataFrame(dtm_countK.astype(int), columns=['<>'] + vocabK)\n",
    "dtm_df_SKL = DataFrame(dtm_countSKL.toarray().astype(int), columns=vocabSKL)\n",
    "\n",
    "\n",
    "print('count DTM from keras.preprocessing.text.Tokenizer():')\n",
    "display(dtm_df_K)\n",
    "\n",
    "print('count DTM from sklearn.feature_extraction.text.CountVectorizer():')\n",
    "dtm_df_SKL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
